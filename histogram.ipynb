{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Any, Dict\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.axes._axes import Axes  # For typing purposes\n",
    "import numpy as np\n",
    "import pyperf\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(result: Dict[str, Any]) -> Dict[str, np.ndarray]:\n",
    "    \"\"\"Parse data\"\"\"\n",
    "    results = {}\n",
    "\n",
    "    for benchmark in result[\"benchmarks\"]:\n",
    "        if \"metadata\" in benchmark:\n",
    "            name = benchmark[\"metadata\"][\"name\"]\n",
    "        else:\n",
    "            name = result[\"metadata\"][\"name\"]\n",
    "        data = []\n",
    "        for run in benchmark[\"runs\"]:\n",
    "            data.extend(run.get(\"values\", []))\n",
    "        results[name] = np.array(data, dtype=np.float64)\n",
    "        results[name].sort()\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "run = \"run6\"\n",
    "\n",
    "file1 = \"python3-11-3-low-01\"\n",
    "file2 = \"python3-11-3-low-02\"\n",
    "\n",
    "file1_path = f\"results/{run}/bm-{file1}.json\"\n",
    "file2_path = f\"results/{run}/bm-{file2}.json\"\n",
    "\n",
    "with open(file1_path) as fb, open(file2_path) as fh:\n",
    "    run1 = get_data(json.load(fb))\n",
    "    run2 = get_data(json.load(fh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure that benchmarks match\n",
    "if run1.keys() != run2.keys():\n",
    "    raise Exception(\"The benchmarking suites are not the same size\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive outlier removal\n",
    "for name in run1.keys():\n",
    "    run1[name] = run1[name][:45]\n",
    "    run2[name] = run2[name][:45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original outlier removal\n",
    "def remove_outliers(values: np.ndarray, m: int = 2):\n",
    "    return values[abs(values - np.mean(values)) < m * np.std(values)]\n",
    "\n",
    "for name in run1.keys():\n",
    "    run1[name] = remove_outliers(run1[name])\n",
    "    run2[name] = remove_outliers(run2[name])\n",
    "\n",
    "    if len(run1[name]) > len(run2[name]):\n",
    "        run1[name] = run1[name][np.round(np.linspace(0, len(run1[name]) - 1, len(run2[name]))).astype(int)]\n",
    "    elif len(run1[name]) < len(run2[name]):\n",
    "        run2[name] = run2[name][np.round(np.linspace(0, len(run2[name]) - 1, len(run1[name]))).astype(int)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dist_plot(ax: Axes, base: np.ndarray, head: np.ndarray) -> None:\n",
    "    # The density set to `True` makes the integral of the histogram 1.\n",
    "    ax.hist(base, alpha=0.5, label='Run 1', density=True)\n",
    "    ax.hist(head, alpha=0.5, label='Run 2', density=True)\n",
    "\n",
    "    # ax.set_xscale('log')\n",
    "    ax.xaxis.set_major_formatter(lambda val, _: f\"{val:4.1g}s\")\n",
    "\n",
    "    x1 = np.linspace(base.mean() - 3 * base.std(), base.mean() + 3 * base.std(), 100)\n",
    "    y1 = stats.norm.pdf(x1, base.mean(), base.std())\n",
    "    ax.plot(x1, y1, label='Run 1 (Normal Dist.)', color=\"blue\")\n",
    "\n",
    "    x2 = np.linspace(head.mean() - 3 * head.std(), head.mean() + 3 * head.std(), 100)\n",
    "    y2 = stats.norm.pdf(x2, head.mean(), head.std())\n",
    "    ax.plot(x2, y2, label='Run 2 (Normal Dist.)', color=\"orange\")\n",
    "\n",
    "    ax.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_cell(table, row: int, name: str, val: str) -> None:\n",
    "    default_c = table._cells[(0, 0)]\n",
    "    c_height = default_c._height\n",
    "    c_width = default_c._width\n",
    "\n",
    "    # I think matplotlib enforces the same number of cells in each row.\n",
    "    # Therefore i use two cells and remove one border.\n",
    "    table.add_cell(row, -1, text=name, loc='left', width=c_width, height=c_height)\n",
    "    table.add_cell(row, 0, text=val, loc='center', width=c_width, height=c_height).visible_edges = 'BTL'\n",
    "    table.add_cell(row, 1, text='', width=c_width, height=c_height).visible_edges = 'BRT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_table(ax: Axes, base: np.ndarray, head: np.ndarray) -> None:\n",
    "    c_labels = [\"Run 1\", \"Run 2\"]\n",
    "    r_labels = [\n",
    "        \"Mean\",\n",
    "        \"Variance\",\n",
    "        \"Skewness\",\n",
    "        \"Variation\",\n",
    "        \"Minimum\",\n",
    "        \"Maximum\",\n",
    "    ]\n",
    "\n",
    "    data = [\n",
    "        [base.mean(), head.mean()],  # Empirical mean\n",
    "        [base.var(), head.var()],  # Variance\n",
    "        [stats.skew(base), stats.skew(head)],  # Sample Skewness\n",
    "        [stats.variation(base), stats.variation(head)],  # Coefficient of variation\n",
    "        [base.min(), head.min()],  # Minimum\n",
    "        [base.max(), head.max()],  # Maximum\n",
    "    ]\n",
    "    data = [[f\"{b:4.1g}\", f\"{h:4.1g}\"] for b, h in data]  # Round to 4 decimal points\n",
    "\n",
    "    table = ax.table(cellText=data, loc='center', cellLoc='center', rowLabels=r_labels, colLabels=c_labels, colWidths=[.3, .3])\n",
    "    table.set_fontsize(11)\n",
    "\n",
    "    _, p_val = stats.ttest_ind(base, head)  # P-value\n",
    "    deg_freedom = len(base) + len(head) - 2\n",
    "    critical_value = pyperf._utils.tdist95conf_level(deg_freedom)\n",
    "    t_score = pyperf._utils.tscore(base, head)\n",
    "    is_significant, _ = pyperf._utils.is_significant(base, head)\n",
    "    \n",
    "    # Round\n",
    "    p_val = f\"{p_val:4.1g}\"\n",
    "    t_score = f\"{t_score:4.1g}\"\n",
    "\n",
    "    add_cell(table, 7, 'P-value', p_val)\n",
    "    add_cell(table, 8, 'Deg. of freedom', deg_freedom)\n",
    "    add_cell(table, 9, 'Critical value', critical_value)\n",
    "    add_cell(table, 10, 'T-Score', t_score)\n",
    "    add_cell(table, 11, 'Significant', is_significant)\n",
    "\n",
    "    ax.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the logarithm of all values\n",
    "for name in run1.keys():\n",
    "    run1[name] = np.abs(np.log(run1[name]))\n",
    "    run2[name] = np.abs(np.log(run2[name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = False\n",
    "\n",
    "if debug:\n",
    "    fig, axs = pyplot.subplots(3, 2, figsize=(13, 3 * 3), layout=\"constrained\", width_ratios=[.7, .3])\n",
    "else:\n",
    "    fig, axs = pyplot.subplots(len(run1), 2, figsize=(13, 3 * len(run1)), layout=\"constrained\", width_ratios=[.7, .3])\n",
    "\n",
    "# Sort by t-score\n",
    "pairs = []\n",
    "significant = 0\n",
    "for name in run1.keys():\n",
    "    t_score = pyperf._utils.tscore(run1[name], run2[name])\n",
    "    pairs.append((name, t_score))\n",
    "    sig, _ = pyperf._utils.is_significant(run1[name], run2[name])\n",
    "    if sig:\n",
    "        significant += 1\n",
    "pairs = sorted(pairs, key=lambda x: abs(x[1]), reverse=True)\n",
    "\n",
    "ax_counter = 0\n",
    "\n",
    "for name, _ in pairs:\n",
    "    axs[ax_counter][0].set_title(name)\n",
    "    generate_dist_plot(axs[ax_counter][0], run1[name], run2[name])\n",
    "    \n",
    "    generate_table(axs[ax_counter][1], run1[name], run2[name])\n",
    "    ax_counter += 1\n",
    "\n",
    "    if debug and ax_counter == 3:\n",
    "        break\n",
    "\n",
    "title = f\"\"\"Comparision of: {file1} and {file2}\n",
    "    Significant: {significant}, out of: {len(run1)}\n",
    "\"\"\"\n",
    "fig.suptitle(title, fontsize=16)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "without_removal = {}\n",
    "naive_removal = {}\n",
    "\n",
    "for name in run1.keys():\n",
    "    _, p_val = stats.ttest_ind(run1[name], run2[name])\n",
    "    without_removal[name] = p_val\n",
    "\n",
    "for name in run1.keys():\n",
    "    # run1[name] = run1[name][:45]\n",
    "    # run2[name] = run2[name][:45]\n",
    "\n",
    "    run1[name] = run1[name][abs(run1[name] - np.mean(run1[name])) < 2 * np.std(run1[name])]\n",
    "    run2[name] = run2[name][abs(run2[name] - np.mean(run2[name])) < 2 * np.std(run2[name])]\n",
    "\n",
    "\n",
    "for name in run1.keys():\n",
    "    _, p_val = stats.ttest_ind(run1[name], run2[name])\n",
    "    naive_removal[name] = p_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "\n",
    "for name in without_removal.keys():\n",
    "    if without_removal[name] < naive_removal[name]:\n",
    "        print(f\"Name: {name}\")\n",
    "        print(without_removal[name])\n",
    "        print(naive_removal[name])\n",
    "        counter += 1\n",
    "\n",
    "print(f\"Improved: {counter}\")\n",
    "print(f\"Out of {len(without_removal)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
